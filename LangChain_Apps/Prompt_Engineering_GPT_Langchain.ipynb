{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6d014ee-e3b7-409c-948b-ac0152f49563",
   "metadata": {},
   "source": [
    "# Prompt Engineering using GPT models and LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a610d9c-089e-4b41-803d-17024f68c51a",
   "metadata": {},
   "source": [
    "This notebook contains useful prompt engineering conepts and techniques for learning purpose. The notebook is based on online materials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4de2a21d-1d16-4bef-b401-64760a2b9735",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 5522,
    "lastExecutedAt": 1703683715152,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Install openai.\n!pip install openai==0.28.0 langchain==0.0.293 typing-extensions==4.8.0 pandas==2.0.3",
    "outputsMetadata": {
     "0": {
      "height": 616,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai==0.28.0 in /home/repl/.local/lib/python3.8/site-packages (0.28.0)\n",
      "Requirement already satisfied: langchain==0.0.293 in /home/repl/.local/lib/python3.8/site-packages (0.0.293)\n",
      "Requirement already satisfied: typing-extensions==4.8.0 in /home/repl/.local/lib/python3.8/site-packages (4.8.0)\n",
      "Requirement already satisfied: pandas==2.0.3 in /home/repl/.local/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai==0.28.0) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai==0.28.0) (4.64.0)\n",
      "Requirement already satisfied: aiohttp in /home/repl/.local/lib/python3.8/site-packages (from openai==0.28.0) (3.9.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.8/dist-packages (from langchain==0.0.293) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.8/dist-packages (from langchain==0.0.293) (1.4.40)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from langchain==0.0.293) (4.0.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /home/repl/.local/lib/python3.8/site-packages (from langchain==0.0.293) (0.5.14)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.38 in /home/repl/.local/lib/python3.8/site-packages (from langchain==0.0.293) (0.0.75)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /home/repl/.local/lib/python3.8/site-packages (from langchain==0.0.293) (2.8.6)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.8/dist-packages (from langchain==0.0.293) (1.23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.8/dist-packages (from langchain==0.0.293) (1.10.12)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/repl/.local/lib/python3.8/site-packages (from langchain==0.0.293) (8.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/dist-packages (from pandas==2.0.3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas==2.0.3) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/repl/.local/lib/python3.8/site-packages (from pandas==2.0.3) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai==0.28.0) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai==0.28.0) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai==0.28.0) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai==0.28.0) (1.3.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai==0.28.0) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/repl/.local/lib/python3.8/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.293) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.293) (0.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas==2.0.3) (1.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai==0.28.0) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.20->openai==0.28.0) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.20->openai==0.28.0) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.20->openai==0.28.0) (2019.11.28)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.293) (1.1.3)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.293) (21.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.293) (0.4.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.293) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "# Install openai.\n",
    "!pip install openai==0.28.0 langchain==0.0.293 typing-extensions==4.8.0 pandas==2.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d301524-67c0-4894-8e2a-72787de3c9bc",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 50,
    "lastExecutedAt": 1703683715203,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import the os package.\nimport os\n\n# Import the openai package.\nimport openai\n\n# Set openai.api_key to the OPENAI_API_KEY environment variable.\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   },
   "outputs": [],
   "source": [
    "# Import the os package.\n",
    "import os\n",
    "\n",
    "# Import the openai package.\n",
    "import openai\n",
    "\n",
    "# Set openai.api_key to the OPENAI_API_KEY environment variable.\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e7d533-4a77-4c17-a9c2-22b4a76b458f",
   "metadata": {},
   "source": [
    "We import both complete and chat complete models. Completion models include gpt-1, gpt-2, and gpt-3 etc. Chat completion models include gpt-3.5-turbo and gpt-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e08d7737-e753-4e54-9ae4-b65e365bf36f",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 47,
    "lastExecutedAt": 1703683715251,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import OpenAI.\nfrom langchain.llms import OpenAI\n\n# Import ChatOpenAI.\nfrom langchain.chat_models import ChatOpenAI"
   },
   "outputs": [],
   "source": [
    "# Import OpenAI.\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Import ChatOpenAI.\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303fc31e-5f83-41a3-a078-e929a11e8bf0",
   "metadata": {},
   "source": [
    "## 1. Import the Financial News Headlines Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c1b04e-0de7-4050-950e-4f64dfc6a58d",
   "metadata": {},
   "source": [
    "A small sample of financial headlines is stored in `financial_headlines.txt`.\n",
    "\n",
    "Our first step is to read in the text file and store the headlines in a Python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b5638c5-9db0-4731-8170-e7b6c1a99697",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 48,
    "lastExecutedAt": 1703683715300,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Open the text file and read its lines.\nheadlines = []\nwith open(\"financial_headlines.txt\") as f:\n    headlines = f.readlines()\n\nheadlines = [line.strip(\"\\n\") for line in headlines]\n\n# Print all headlines.\nprint(headlines)",
    "outputsMetadata": {
     "0": {
      "height": 157,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\", 'Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .', 'Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .', 'Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .', \"Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .\", 'Finnish Outokumpu Technology has been awarded several new grinding technology contracts .']\n"
     ]
    }
   ],
   "source": [
    "# Open the text file and read its lines.\n",
    "headlines = []\n",
    "with open(\"financial_headlines.txt\") as f:\n",
    "    headlines = f.readlines()\n",
    "\n",
    "headlines = [line.strip(\"\\n\") for line in headlines]\n",
    "\n",
    "# Print all headlines.\n",
    "print(headlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f389f489-eddd-45c0-84d7-44dd8f9ca5b3",
   "metadata": {},
   "source": [
    "## 2: Setting up Prompt Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f0adf8-630d-4738-95a2-9a8abc0edd67",
   "metadata": {},
   "source": [
    "Prompt templates help us to organize our code to be modular, scalable and reusable by its following properties:\n",
    "* allows for dynamic prompts\n",
    "* built-in verification tools \n",
    "* easily saved, versioned and integrated into the code base\n",
    "\n",
    "We will set up Prompt Templates from the `langchain` package to automatically determine financial sentiment from the headlines and extract relevant company names. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df906cad-1b81-4081-ba84-50e42c7ee011",
   "metadata": {},
   "source": [
    "### 2.1 PromptTemplate for completion models\n",
    "* Prompt templates allow us to insert the values dynamically\n",
    "* As demonstrated here, we can change the values of 'headline' and build different prompts for different use cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5c74f6d-fad2-4a52-a2e4-653768d33c33",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 48,
    "lastExecutedAt": 1703683715348,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import the PromptTemplate class.\nfrom langchain.prompts import PromptTemplate\n\n# Create a dynamic template to analyze a single headline.\nprompt_template = PromptTemplate.from_template(\"Analyze the following financial headline for sentiment: {headline}\")\n\n# Format the prompt template on the first headline of the dataset.\nformatted_prompt = prompt_template.format(headline=headlines[0])\n\n# Print the formatted template.\nprint(formatted_prompt)",
    "outputsMetadata": {
     "0": {
      "height": 57,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze the following financial headline for sentiment: Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\n"
     ]
    }
   ],
   "source": [
    "# Import the PromptTemplate class.\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Create a dynamic template to analyze a single headline.\n",
    "prompt_template = PromptTemplate.from_template(\"Analyze the following financial headline for sentiment: {headline}\")\n",
    "\n",
    "# Format the prompt template on the first headline of the dataset.\n",
    "formatted_prompt = prompt_template.format(headline=headlines[0])\n",
    "\n",
    "# Print the formatted template.\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d858c71f-a8eb-4115-a747-7bd643595ea5",
   "metadata": {},
   "source": [
    "### 2.2 ChatPromptTemplate\n",
    "\n",
    "a `ChatPromptTemplate`are used to communicate with conversational models like GPT-4 and GPT-3.5-Turbo. One advantage of this type of the template is that we can define a system message.\n",
    "\n",
    "In terms of prompt engineering, system messages can help to improve the quality of the output by the following ways:\n",
    "- Define a role: *\"You are a X\", \"Your role is to do X\", ...*\n",
    "- Define a tone of voice: *\"Respond in a formal manner\", \"Use customer-oriented language\", ...*\n",
    "- Define restrictions on output format: *\"The format of the output is X\", \"The output is strictly limited to X, Y, Z\", ...*\n",
    "- Define a scope: *\"Only answer questions on topic X\", \"If the user questions is not about X, answer with Y\", ...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d621445-3804-442d-8040-8405c6c9c83f",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 53,
    "lastExecutedAt": 1703683715401,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import the ChatPromptTemplate class.\nfrom langchain.prompts import ChatPromptTemplate\n\n# Define the system message and define the role of the chat model.\nsystem_message = \"\"\"You are performing sentiment analysis on news headlines regarding financial analysis. \nThis sentiment is to be used to advice financial analysts. \nThe format of the output has to be consistent. \nThe output is strictly limited to any of the following options: [positive, negative, neutral].\"\"\"\n\n# Initialize a new ChatPromptTemplate with a system message and human message.\nchat_template = ChatPromptTemplate.from_messages([\n    ('system', system_message),\n    ('human', \"Analyze the following financial headline for sentiment: {headline}\")\n])\n\n# Format the ChatPromptTemplate.\nformatted_chat_template = chat_template.format(headline=headlines[0])\n\n# Print the formatted template.\nprint(formatted_chat_template)",
    "outputsMetadata": {
     "0": {
      "height": 137,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are performing sentiment analysis on news headlines regarding financial analysis. \n",
      "This sentiment is to be used to advice financial analysts. \n",
      "The format of the output has to be consistent. \n",
      "The output is strictly limited to any of the following options: [positive, negative, neutral].\n",
      "Human: Analyze the following financial headline for sentiment: Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\n"
     ]
    }
   ],
   "source": [
    "# Import the ChatPromptTemplate class.\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Define the system message and define the role of the chat model.\n",
    "system_message = \"\"\"You are performing sentiment analysis on news headlines regarding financial analysis. \n",
    "This sentiment is to be used to advice financial analysts. \n",
    "The format of the output has to be consistent. \n",
    "The output is strictly limited to any of the following options: [positive, negative, neutral].\"\"\"\n",
    "\n",
    "# Initialize a new ChatPromptTemplate with a system message and human message.\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', system_message),\n",
    "    ('human', \"Analyze the following financial headline for sentiment: {headline}\")\n",
    "])\n",
    "\n",
    "# Format the ChatPromptTemplate.\n",
    "formatted_chat_template = chat_template.format(headline=headlines[0])\n",
    "\n",
    "# Print the formatted template.\n",
    "print(formatted_chat_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec62e063-c2bf-42c9-bb54-f774e3f13ff2",
   "metadata": {},
   "source": [
    "## 3: Setting up LLM Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907abbe1-0ecb-4b33-8a46-8471c214df38",
   "metadata": {},
   "source": [
    "LLM Chains allow us to combine a model with a prompt template. These chains can be created for both *completion models* and *chat completion models*.\n",
    "\n",
    "LLM Chains can be used to \"chain\" prompt flows, by using the output of a previous chain as input for the next.\n",
    "\n",
    "Let's set up a chain for a completion model first, using the templates that we've just built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "234126d2-0e6a-4286-8fd9-2ec95eb5a566",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 315,
    "lastExecutedAt": 1703683715716,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import the LLMChain class.\nfrom langchain.chains import LLMChain\n\n# Create the LLMChain by combining a completion model and a prompt.\ncompletion_chain = LLMChain(llm=OpenAI(), prompt=prompt_template)\n\n# Run the LLMChain.\ncompletion_chain.run(headline=headlines[0])"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nPositive'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the LLMChain class.\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Create the LLMChain by combining a completion model and a prompt.\n",
    "completion_chain = LLMChain(llm=OpenAI(), prompt=prompt_template)\n",
    "\n",
    "# Run the LLMChain.\n",
    "completion_chain.run(headline=headlines[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20424b97-c01c-4786-9460-beae26fb8a35",
   "metadata": {},
   "source": [
    "This looks the same as calling a sentimental analysis by open source llm models using hugging face transformers' pipeline, as demonstrated in one of my notebooks, \"using_Huggingface_llms\" notebook, which is also in this repo. The difference here is that we used prompt templates.\n",
    "\n",
    "We can execute on a chat completion model using LLMChain and a chat template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00a8db2b-fd72-421c-9e17-82a47ee460b5",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 795,
    "lastExecutedAt": 1703683716511,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Create the LLMChain by combining a chat completion model and a prompt.\nchat_chain = LLMChain(llm=ChatOpenAI(), prompt=chat_template)\n\n# Run the LLMChain.\nchat_chain.run(headline=headlines[0], system_message=system_message)"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The sentiment of the given financial headline is positive.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the LLMChain by combining a chat completion model and a prompt.\n",
    "chat_chain = LLMChain(llm=ChatOpenAI(), prompt=chat_template)\n",
    "\n",
    "# Run the LLMChain.\n",
    "chat_chain.run(headline=headlines[0], system_message=system_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ab6d2c-87d1-4966-bac0-99f3ba39d195",
   "metadata": {},
   "source": [
    "## 4: Working with Agents and Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709a8d80-fb26-4f83-9cf2-19e6cbb00557",
   "metadata": {},
   "source": [
    "### What are Tools and Agents?\n",
    "\n",
    "We can access (external) tools using the output of the GPT-model. Large language models output only text. In order to call a function (to access a tool) based on the text output of a large language model, we can use agents. They can parse the text output, pick the correct tool and define its input.\n",
    "\n",
    "In this example, we will make use of the `PythonREPLTool`. This allows the GPT-model to run the Python code that it generates, and can be useful for carrying out tasks, such as complicated calculations, which is not what large language models were trained for.\n",
    "\n",
    "Always set the `max_tokens` argument to prevent endless recursive calls!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9016d465-16b8-48d8-af78-3384a113eaa3",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 257,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to calculate the square root of 250\n",
      "Action: Python_REPL\n",
      "Action Input: import math; print(round(math.sqrt(250), 4))\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m15.8114\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 15.8114\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'15.8114'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary classes from langchain.\n",
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "\n",
    "# Instantiate a Python agent, with the PythonREPLTool.\n",
    "agent_executor = create_python_agent(\n",
    "    llm=OpenAI(temperature=0, max_tokens=1000),\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Ask the agent for the solution of a mathematical equation.\n",
    "agent_executor.run(\"What is the square root of 250? Round the answer down to 4 decimals.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8165aae-4ca8-4529-81c0-77cba7faa353",
   "metadata": {},
   "source": [
    "The agent correctly identified PythonREPLTool for the calculation. Now let's demonstrate a more complex task: writing the python code to generate a pandas datafram that contains company names, their sentimental analysis results, and the original headlines. Finally, save the dataframe as a csv file with the file name specified in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b20fd6c7-315d-4a6e-bc31-23a58aa9595b",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 9369,
    "lastExecutedAt": 1703683727294,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Run the agent\nagent_executor.run(f\"\"\"For every of the following headlines, extract the company name and whether the financial sentiment is positive, neutral or negative. \nLoad this data into a pandas dataframe. \nThe dataframe will have three columns: the name of the company, whether the financial sentiment is positive or negative and the headline itself. \nThe dataframe can then be saved in the current working directory under the name financial_analysis.csv.\nIf a csv file already exists with the same name, it should be overwritten.\n\nThe headlines are the following:\n{headlines}\"\"\")",
    "outputsMetadata": {
     "0": {
      "height": 616,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to extract the company name and sentiment from each headline\n",
      "Action: Python_REPL\n",
      "Action Input: \n",
      "import pandas as pd\n",
      "\n",
      "headlines = [\"Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\", 'Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .', 'Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .', 'Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .', \"Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .\", 'Finnish Outokumpu Technology has been awarded several new grinding technology contracts .']\n",
      "\n",
      "company_names = []\n",
      "sentiments = []\n",
      "\n",
      "for headline in headlines:\n",
      "    if 'profit' in headline or 'awarded' in headline:\n",
      "        sentiments.append('positive')\n",
      "    elif 'loss' in headline:\n",
      "        sentiments.append('negative')\n",
      "    else:\n",
      "        sentiments.append('neutral')\n",
      "    company_names.append(headline.split(' ')[1])\n",
      "\n",
      "df = pd.DataFrame({'company_name': company_names, 'sentiment': sentiments, 'headline': headlines})\n",
      "df.to_csv('financial_analysis.csv', index=False)\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The dataframe has been saved in the current working directory under the name financial_analysis.csv. It contains three columns: the name of the company, whether the financial sentiment is positive or negative and the headline itself.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The dataframe has been saved in the current working directory under the name financial_analysis.csv. It contains three columns: the name of the company, whether the financial sentiment is positive or negative and the headline itself.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the agent\n",
    "agent_executor.run(f\"\"\"For every of the following headlines, extract the company name and whether the financial sentiment is positive, neutral or negative. \n",
    "Load this data into a pandas dataframe. \n",
    "The dataframe will have three columns: the name of the company, whether the financial sentiment is positive or negative and the headline itself. \n",
    "The dataframe can then be saved in the current working directory under the name financial_analysis.csv.\n",
    "If a csv file already exists with the same name, it should be overwritten.\n",
    "\n",
    "The headlines are the following:\n",
    "{headlines}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577028c8-4781-4fd7-a723-caf42469a6ae",
   "metadata": {},
   "source": [
    "Now, let' check if csv file contains the information about company names, the sentimental analysis results and original headline content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "910ab6a3-7331-40a5-950e-462344b0642c",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 54,
    "lastExecutedAt": 1703683727348,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import pandas as pd\ndata = pd.read_csv(\"financial_analysis.csv\")\ndata",
    "outputsMetadata": {
     "0": {
      "height": 223,
      "type": "dataFrame"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/com.datacamp.data-table.v2+json": {
       "table": {
        "data": {
         "company_name": [
          "Aktia",
          "measuring",
          "pharmaceuticals",
          ",",
          "Metso",
          "Outokumpu"
         ],
         "headline": [
          "Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .",
          "Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .",
          "Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .",
          "Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .",
          "Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .",
          "Finnish Outokumpu Technology has been awarded several new grinding technology contracts ."
         ],
         "index": [
          0,
          1,
          2,
          3,
          4,
          5
         ],
         "sentiment": [
          "positive",
          "negative",
          "positive",
          "negative",
          "positive",
          "positive"
         ]
        },
        "schema": {
         "fields": [
          {
           "name": "index",
           "type": "integer"
          },
          {
           "name": "company_name",
           "type": "string"
          },
          {
           "name": "sentiment",
           "type": "string"
          },
          {
           "name": "headline",
           "type": "string"
          }
         ],
         "pandas_version": "1.4.0",
         "primaryKey": [
          "index"
         ]
        }
       },
       "total_rows": 6,
       "truncation_type": null
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aktia</td>\n",
       "      <td>positive</td>\n",
       "      <td>Finnish Aktia Group 's operating profit rose t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>measuring</td>\n",
       "      <td>negative</td>\n",
       "      <td>Finnish measuring equipment maker Vaisala Oyj ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pharmaceuticals</td>\n",
       "      <td>positive</td>\n",
       "      <td>Finnish pharmaceuticals company Orion reports ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>,</td>\n",
       "      <td>negative</td>\n",
       "      <td>Tiimari , the Finnish retailer , reported to h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Metso</td>\n",
       "      <td>positive</td>\n",
       "      <td>Finnish Metso Paper has been awarded a contrac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Outokumpu</td>\n",
       "      <td>positive</td>\n",
       "      <td>Finnish Outokumpu Technology has been awarded ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      company_name sentiment                                           headline\n",
       "0            Aktia  positive  Finnish Aktia Group 's operating profit rose t...\n",
       "1        measuring  negative  Finnish measuring equipment maker Vaisala Oyj ...\n",
       "2  pharmaceuticals  positive  Finnish pharmaceuticals company Orion reports ...\n",
       "3                ,  negative  Tiimari , the Finnish retailer , reported to h...\n",
       "4            Metso  positive  Finnish Metso Paper has been awarded a contrac...\n",
       "5        Outokumpu  positive  Finnish Outokumpu Technology has been awarded ..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"financial_analysis.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bb73ca-089b-4bdf-ba9f-e2efbe3174f0",
   "metadata": {},
   "source": [
    "## 5: Adding Few Shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe98ba4-9d30-40e7-8a80-d8b780a48105",
   "metadata": {},
   "source": [
    "Few shot learning means adding examples into our prompt to guide the model for more relavant responses. \n",
    "\n",
    "There are three categories of N shot learning:\n",
    "- Few shot leaning (multiple examples)\n",
    "- Single shot learning (one example)\n",
    "- Zero shot leaning (no examples)\n",
    "\n",
    "Few shot learning generally gives better results, as more information is provided about our desired results.\n",
    "\n",
    "The next section showed the following techniques\n",
    "* how to build the prompts with examples in few shot learing. It is pretty straightforward: you just embed the examples in the prompt templates and run the model!\n",
    "* how to format the output as a comma separated list using langchain's output parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78e963c2-d4a5-409b-b4b7-7a1d30a13346",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 478,
    "lastExecutedAt": 1703684286108,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import the CommaSeparatedListOutputParser class.\nfrom langchain.output_parsers import CommaSeparatedListOutputParser\n\n# Instantiate the output parser.\noutput_parser = CommaSeparatedListOutputParser()\n\n# Get the format instructions from the output parser.\nformat_instructions = output_parser.get_format_instructions()\n\n# Store the few shot examples in a variable.\nsentiment_examples = \"\"\"\nIf a company is doing financially better than before, the sentiment is positive. For example, when profits or revenue have increased since the last quarter or year, exceeding expectations, a contract is awarded or an acquisition is announced.\nIf the company's profits are decreasing, losses are mounting up or overall performance is not meeting expectations, the sentiment is negative.\nIf nothing positive or negative is mentioned from a financial perspective, the sentiment is neutral.\n\"\"\"\n\n# Instantiate a new prompt template with the format instructions.\nsentiment_template = PromptTemplate(\n    template=\"Get the financial sentiment of each of the following headlines. {few_shot_examples} The output is strictly limited to any of the following options: ['Positive', 'Negative', 'Neutral']: {headlines}.\\n{format_instructions}\",\n    input_variables =[\"headlines\", \"few_shot_examples\"],\n    partial_variables={\"format_instructions\": format_instructions}    \n)\n\n# Format the template.\nformatted_sentiment_template = sentiment_template.format(headlines=headlines, few_shot_examples=sentiment_examples)\n\n# Run the model on the formatted template.\nmodel = OpenAI(temperature=0)\n_output = model(formatted_sentiment_template)\n\n# Parse the model output.\nsentiments = output_parser.parse(_output)\n\nprint(sentiments)",
    "outputsMetadata": {
     "0": {
      "height": 37,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive']\n"
     ]
    }
   ],
   "source": [
    "# Import the CommaSeparatedListOutputParser class.\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "# Instantiate the output parser.\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "# Get the format instructions from the output parser.\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "# Store the few shot examples in a variable.\n",
    "sentiment_examples = \"\"\"\n",
    "If a company is doing financially better than before, the sentiment is positive. For example, when profits or revenue have increased since the last quarter or year, exceeding expectations, a contract is awarded or an acquisition is announced.\n",
    "If the company's profits are decreasing, losses are mounting up or overall performance is not meeting expectations, the sentiment is negative.\n",
    "If nothing positive or negative is mentioned from a financial perspective, the sentiment is neutral.\n",
    "\"\"\"\n",
    "\n",
    "# Instantiate a new prompt template with the format instructions.\n",
    "sentiment_template = PromptTemplate(\n",
    "    template=\"Get the financial sentiment of each of the following headlines. {few_shot_examples} The output is strictly limited to any of the following options: ['Positive', 'Negative', 'Neutral']: {headlines}.\\n{format_instructions}\",\n",
    "    input_variables =[\"headlines\", \"few_shot_examples\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}    \n",
    ")\n",
    "\n",
    "# Format the template.\n",
    "formatted_sentiment_template = sentiment_template.format(headlines=headlines, few_shot_examples=sentiment_examples)\n",
    "\n",
    "# Run the model on the formatted template.\n",
    "model = OpenAI(temperature=0)\n",
    "_output = model(formatted_sentiment_template)\n",
    "\n",
    "# Parse the model output.\n",
    "sentiments = output_parser.parse(_output)\n",
    "\n",
    "print(sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81d3a0b-b9ac-4def-b19a-b501a42d9ff2",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9ba593-30fa-43b5-9b18-2bd6c7e4087e",
   "metadata": {},
   "source": [
    "This notebook demonstates several commonly used prompt engineering techniques, including\n",
    "- Using SystemMessage to optimize the outcomes\n",
    "- Setting up prompt templates \n",
    "- Using LLMChains\n",
    "- Using LangChain Agents and Tools to add additional functionalities inculding complex calculations and writing code, as demonstrated in this notebook, to generative AI projects\n",
    "- How to build prompts for few shot learning"
   ]
  }
 ],
 "metadata": {
  "editor": "DataCamp Workspace",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
